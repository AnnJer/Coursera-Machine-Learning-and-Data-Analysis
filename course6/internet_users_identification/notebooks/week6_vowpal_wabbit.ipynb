{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Идентификация пользователей по посещенным веб-страницам\n",
    "<img src='http://i.istockimg.com/file_thumbview_approve/21546327/5/stock-illustration-21546327-identification-de-l-utilisateur.jpg'>\n",
    "\n",
    "# <center>Неделя 6.  Vowpal Wabbit\n",
    "\n",
    "На этой неделе мы познакомимся с популярной библиотекой Vowpal Wabbit и попробуем ее на данных соревнования. Знакомиться будем с помощью [данных](http://scikit-learn.org/stable/datasets/twenty_newsgroups.html) Scikit-learn по новостям, сначала в режиме бинарной классификации, затем – в многоклассовом режиме. Далее будем классифицировать рецензии к фильмам с сайта IMDB. Наконец, применим Vowpal Wabbit к нашему соревнованию. Материала немало, но Vowpal Wabbit того стоит!\n",
    "\n",
    "**План 6 недели:**\n",
    "- Часть 1. Тьюториал по Vowpal Wabbit. Новости. Бинарная классификация\n",
    "- Часть 2. Тьюториал по Vowpal Wabbit. Новости. Многоклассовая классификация\n",
    "- Часть 3. Тьюториал по Vowpal Wabbit. Рецензии к фильмам IMDB\n",
    "- Часть 4. Применение Vowpal Wabbit к данным по посещению сайтов\n",
    "\n",
    "\n",
    "**В этой части проекта Вам могут быть полезны видеозаписи следующих лекций курса \"Обучение на размеченных данных\":**\n",
    "   - [Стохатический градиентный спуск](https://www.coursera.org/learn/supervised-learning/lecture/xRY50/stokhastichieskii-ghradiientnyi-spusk)\n",
    "   - [Линейные модели. Sklearn.linear_model. Классификация](https://www.coursera.org/learn/supervised-learning/lecture/EBg9t/linieinyie-modieli-sklearn-linear-model-klassifikatsiia)\n",
    "   \n",
    "Также будет полезна [презентация](https://github.com/esokolov/ml-course-msu/blob/master/ML15/lecture-notes/Sem08_vw.pdf) лектора специализации Евгения Соколова. И, конечно же, [документация](https://github.com/JohnLangford/vowpal_wabbit/wiki) Vowpal Wabbit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Тьюториал по Vowpal Wabbit. Новости. Бинарная классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vowpal Wabbit (VW) является одной из наиболее широко используемых библиотек в индустрии. Её отличает высокая скорость работы и поддержка большого количества различных режимов обучения. Особый интерес для больших и высокоразмерных данных представляет онлайн-обучение – самая сильная сторона библиотеки. \n",
    "\n",
    "\n",
    "Основным интерфейсом для работы с VW является shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "import sklearn.datasets\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы изучить возможные режимы работы vw, воспользуемся справкой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!vw --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Vowpal Wabbit считывает данные из файла или стандартного ввода (stdin) в формате, который имеет следующий вид:\n",
    "\n",
    "`[Label] [Importance] [Tag]|Namespace Features |Namespace Features ... |Namespace Features`\n",
    "\n",
    "`Namespace=String[:Value]`\n",
    "\n",
    "`Features=(String[:Value] )*`\n",
    "\n",
    "где [] обозначает необязательные элементы, а (...)\\* означает повтор неопределенное число раз. \n",
    "\n",
    "- **Label** является числом, \"правильным\" ответом. В случае классификации обычно принимает значение 1/-1, а в случае регрессии некоторое вещественное число\n",
    "- **Importance** является числом и отвечает за вес примера при обучении. Это позволяет бороться с проблемой несбалансированных данных, изученной нами ранее\n",
    "- **Tag** является некоторой строкой без пробелов и отвечает за некоторое \"название\" примера, которое сохраняется при предсказании ответа. Для того, чтобы отделить Tag от Importance лучше начинать Tag с символа '.\n",
    "- **Namespace** служит для создания отдельных пространств признаков. В аргументах Namespace именуются по первой букве, это нужно учитывать при выборе их названий\n",
    "- **Features** являются непосредственно признаками объекта внутри **Namespace**. Признаки по умолчанию имеют вес 1.0, но его можно переопределить, к примеру feature:0.1. \n",
    "\n",
    "\n",
    "К примеру, под такой формат подходит следующая строка:\n",
    "\n",
    "```\n",
    "1 1.0 |Subject WHAT car is this |Organization University of Maryland:0.5 College Park\n",
    "```\n",
    "\n",
    "\n",
    "чтобы убедиться в этом, запустим vw с этим обучающим примером:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! echo '1 1.0 |Subject WHAT car is this |Organization Maryland:0.5 College Park' | vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VW является прекрасным инструментом для работы с текстовыми данными. Убедимся в этом с помощью выборки 20newsgroups, содержащей письма из 20 различных тематических рассылок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newsgroups = sklearn.datasets.fetch_20newsgroups('news_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newsgroups['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим первый текстовый документ этой коллекции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = newsgroups['data'][0]\n",
    "target = newsgroups['target_names'][newsgroups['target'][0]]\n",
    "\n",
    "print('-----')\n",
    "print(target)\n",
    "print('-----')\n",
    "print(text.strip())\n",
    "print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Приведем данные к формату Vowpal Wabbit, при этом оставляя только слова не короче 3 символов. Здесь мы не выполняем многие важные в анализе текстов процедуры (стемминг и лемматизацию), но, как увидим, задача и так будет решаться хорошо.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_vw_format(document, label=None):\n",
    "    return str(label or '') + ' |text ' + ' '.join(re.findall('\\w{3,}', \n",
    "                                                              document.lower())) + '\\n'\n",
    "\n",
    "to_vw_format(text, 1 if target == 'rec.autos' else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем выборку на обучающую и тестовую и запишем в файл преобразованные таким образом документы. Будем считать документ положительным, если он относится к рассылке про автомобили **rec.autos**. Так мы построим модель, отличающую письма про автомобили от остальных: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_documents = newsgroups['data']\n",
    "all_targets = [1 if newsgroups['target_names'][target] == 'rec.autos' \n",
    "               else -1 for target in newsgroups['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_documents, test_documents, train_labels, test_labels = \\\n",
    "    train_test_split(all_documents, all_targets, random_state=7)\n",
    "    \n",
    "with open('news_data/20news_train.vw', 'w') as vw_train_data:\n",
    "    for text, target in zip(train_documents, train_labels):\n",
    "        vw_train_data.write(to_vw_format(text, target))\n",
    "with open('news_data/20news_test.vw', 'w') as vw_test_data:\n",
    "    for text in test_documents:\n",
    "        vw_test_data.write(to_vw_format(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим Vowpal Wabbit на сформированном файле. Мы решаем задачу классификации, поэтому зададим функцию потерь в значение hinge (линейный SVM). Построенную модель мы сохраним в соответствующий файл 20news_model.vw:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!vw -d news_data/20news_train.vw --loss_function hinge -f news_data/20news_model.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель обучена. VW выводит достаточно много полезной информации по ходу обучения. Обратите внимание, что average loss снижался по ходу выполнения итераций. Для вычисления функции потерь VW использует еще не просмотренные примеры, поэтому, как правило, эта оценка является корректной. Применим обученную модель на тестовой выборке, сохраняя предсказания в файл с помощью опции -p: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!vw -i news_data/20news_model.vw -t -d news_data/20news_test.vw \\\n",
    "-p news_data/20news_test_predictions.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим полученные предсказания, вычислим AUC и отобразим ROC-кривую:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('news_data/20news_test_predictions.txt') as pred_file:\n",
    "    test_prediction = [float(label) \n",
    "                             for label in pred_file.readlines()]\n",
    "\n",
    "auc = sklearn.metrics.roc_auc_score(test_labels, test_prediction)\n",
    "roc_curve = sklearn.metrics.roc_curve(test_labels, test_prediction)\n",
    "\n",
    "with plt.xkcd():\n",
    "    plt.plot(roc_curve[0], roc_curve[1]);\n",
    "    plt.plot([0,1], [0,1])\n",
    "    plt.xlabel('FPR'); plt.ylabel('TPR'); \n",
    "    plt.title('test AUC = %f' % (auc)); \n",
    "    plt.axis([-0.05,1.05,-0.05,1.05]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученное значения AUC говорит о высоком качестве классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Тьюториал по Vowpal Wabbit. Новости. Многоклассовая классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Используем ту же выборку, что в прошлой части, но решаем задачу многоклассовой классификации. Тут Vowpal Wabbit слегка капризничает – он любит, чтоб метки классов были распределены от 1 до K, где K – число классов в задаче классификации (в нашем случае – 20). Поэтому придется применить LabelEncoder, да еще и +1 потом добавить (LabelEncoder переводит метки в диапазон от 0 до K-1).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_documents = newsgroups['data']\n",
    "topic_encoder = LabelEncoder()\n",
    "all_targets_mult = topic_encoder.fit_transform(newsgroups['target']) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выборки будут те же, а метки поменяются, train_labels_mult и test_labels_mult – векторы меток от 1 до 20.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_documents, test_documents, train_labels_mult, test_labels_mult = \\\n",
    "    train_test_split(all_documents, all_targets_mult, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('news_data/20news_train_mult.vw', 'w') as vw_train_data:\n",
    "    for text, target in zip(train_documents, train_labels_mult):\n",
    "        vw_train_data.write(to_vw_format(text, target))\n",
    "with open('news_data/20news_test_mult.vw', 'w') as vw_test_data:\n",
    "    for text in test_documents:\n",
    "        vw_test_data.write(to_vw_format(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучим Vowpal Wabbit в режиме многоклассовой классификации, передав параметр *oaa* (от \"one against all\"), равный числу классов. Также перечислим параметры, которые можно понастраивать, и от которых качество модели может довольно значительно зависеть (более полно – в официальном [тьюториале](https://github.com/JohnLangford/vowpal_wabbit/wiki/Tutorial) по Vowpal Wabbit):**\n",
    " - темп обучения (-l, по умолчанию 0.5) – коэффициент перед изменением весов модели при каждом изменении\n",
    " - степень убывания темпа обучения (--power_t, по умолчанию 0.5) – на практике проверено, что если темп обучения уменьшается при увеличении числа итераций стохастического градиентного спуска, то минимум функции находится лучше \n",
    " - функция потерь (--loss_function) – от нее, по сути, зависит обучаемый алгоритм\n",
    " - регуляризация (-l1) – тут надо обратить внимание на то, что в VW регуляризация считается для каждого объекта, поэтому коэффициенты регуляризации обычно берутся малыми, около $10^{-20}.$\n",
    " \n",
    " **Дополнительно: в соревновании можно попробовать автоматическую настройку параметров Vowpal Wabbit с Hyperopt. Пока это работает только с Python 2. [Статья](https://habrahabr.ru/company/dca/blog/272697/) на Хабре.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "!vw --oaa 20 news_data/20news_train_mult.vw -f news_data/20news_model_mult.vw \\\n",
    "--loss_function=hinge --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "!vw -i news_data/20news_model_mult.vw -t -d news_data/20news_test_mult.vw \\\n",
    "-p news_data/20news_test_predictions_mult.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('news_data/20news_test_predictions_mult.txt') as pred_file:\n",
    "    test_prediction_mult = [float(label) \n",
    "                             for label in pred_file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_score(test_labels_mult, test_prediction_mult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выведем раскрашенную матрицу ошибок полученного классификатора.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "M = confusion_matrix(test_labels_mult, test_prediction_mult)\n",
    "M_normalized = M.astype('float') / M.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "im = plt.imshow(M_normalized, interpolation='nearest')\n",
    "plt.colorbar(im, shrink=0.71)\n",
    "tick_marks = np.arange(len(newsgroups['target_names']))\n",
    "plt.xticks(tick_marks - 0.5, newsgroups['target_names'], rotation=45)\n",
    "plt.yticks(tick_marks, newsgroups['target_names'])\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True topic')\n",
    "plt.xlabel('Predicted topic')\n",
    "plt.title('Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. Тьюториал по Vowpal Wabbit. Рецензии к фильмам IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В этой части мы будем заниматься бинарной классификацией отзывов к фильмам, опубликованным на сайте IMDB. Обратите внимание, насколько быстро будет работать Vowpal Wabbit.**\n",
    "\n",
    "**Используем функцию *load_files* из sklearn.datasets для загрузки отзывов по фильмам [отсюда](https://yadi.sk/d/Tg1Tflur333iLr). Скачайте данные и положите рядом с этой тетрадкой в каталог *imdb_reviews* (в нем должны быть каталоги *train* и *test*). Разархивирование может занять несколько минут – там 100 тыс. файлов. В обучающей и тестовой выборках по 12500 тысяч хороших и плохих отзывов к фильмам. Отделим данные (собственно тексты) от меток.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews_train = load_files('imdb_reviews/train/')\n",
    "text_train, y_train = reviews_train.data, reviews_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of documents in training data: %d\" % len(text_train))\n",
    "print(np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То же самое с тестовой выборкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews_test = load_files('imdb_reviews/test/')\n",
    "text_test, y_test = reviews_test.data, reviews_train.target\n",
    "print(\"Number of documents in test data: %d\" % len(text_test))\n",
    "print(np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примеры отзывов и соответствующих меток.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train[0] # хороший отзыв"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train[1] # плохой отзыв"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Будем использовать ранее написанную функцию to_vw_format.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_vw_format(str(text_train[1]), 1 if y_train[0] == 1 else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подготовим обучающую (movie_reviews_train.vw), отложенную (movie_reviews_valid.vw) и тестовую (movie_reviews_test.vw) выборки для Vowpal Wabbit. 70% исходной обучаюшей выборки оставим под обучение, 30% – под отложенную выборку.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_share = int(0.7 * len(text_train))\n",
    "train, valid = text_train[:train_share], text_train[train_share:]\n",
    "train_labels, valid_labels = y_train[:train_share], y_train[train_share:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(train_labels), len(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('imdb_reviews/movie_reviews_train.vw', 'w') as vw_train_data:\n",
    "    for text, target in zip(train, train_labels):\n",
    "        vw_train_data.write(to_vw_format(str(text), 1 if target == 1 else -1))\n",
    "with open('imdb_reviews/movie_reviews_valid.vw', 'w') as vw_train_data:\n",
    "    for text, target in zip(valid, valid_labels):\n",
    "        vw_train_data.write(to_vw_format(str(text), 1 if target == 1 else -1))\n",
    "with open('imdb_reviews/movie_reviews_test.vw', 'w') as vw_test_data:\n",
    "    for text in text_test:\n",
    "        vw_test_data.write(to_vw_format(str(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head -2 imdb_reviews/movie_reviews_train.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head -2 imdb_reviews/movie_reviews_valid.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head -2 imdb_reviews/movie_reviews_test.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучим модель Vowpal Wabbit со следующими аргументами:**\n",
    "\n",
    " - -d, путь к обучающей выборке (соотв. файл .vw )\n",
    " - --loss_function – hinge (хотя можно и поэкспериментировать с другими)\n",
    " - -f – путь к файлу, в который запишется модель (можно тоже в формате .vw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!vw -d imdb_reviews/movie_reviews_train.vw \\\n",
    "--loss_function hinge -f imdb_reviews/movie_reviews_model.vw --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сделаем прогноз для отложенной выборки с помощью обученной модели Vowpal Wabbit, передав следующие аргументы:**\n",
    " - -i –путь к обученной модели (соотв. файл .vw)\n",
    " - -t -d – путь к отложенной выборке (соотв. файл .vw)\n",
    " - -p – путь к txt-файлу, куда запишутся прогнозы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!vw -i imdb_reviews/movie_reviews_model.vw -t -d imdb_reviews/movie_reviews_valid.vw \\\n",
    "-p imdb_reviews/movie_valid_pred.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Считаем прогноз из файла и посчитаем долю правильных ответов и ROC AUC. Учтем, что VW выводит оценки вероятности принадлежности к классу +1. Эти оценки распределены на [-1, 1], поэтому бинарным ответом алгоритма (0 или 1) будем попросту считать тот факт, что оценка получилась положительной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('imdb_reviews/movie_valid_pred.txt') as pred_file:\n",
    "    valid_prediction = [float(label) \n",
    "                             for label in pred_file.readlines()]\n",
    "print(\"Accuracy: {}\".format(round(accuracy_score(valid_labels, \n",
    "               [int(pred_prob > 0) for pred_prob in valid_prediction]), 3)))\n",
    "print(\"AUC: {}\".format(round(roc_auc_score(valid_labels, valid_prediction), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Сделаем то же самое для тестовой выборки.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!vw -i imdb_reviews/movie_reviews_model.vw -t -d imdb_reviews/movie_reviews_test.vw \\\n",
    "-p imdb_reviews/movie_test_pred.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('imdb_reviews/movie_test_pred.txt') as pred_file:\n",
    "    test_prediction = [float(label) \n",
    "                             for label in pred_file.readlines()]\n",
    "print(\"Accuracy: {}\".format(round(accuracy_score(y_test, \n",
    "               [int(pred_prob > 0) for pred_prob in test_prediction]), 3)))\n",
    "print(\"AUC: {}\".format(round(roc_auc_score(y_test, test_prediction), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Попробуем улучшить прогноз за счет задействования биграмм.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!vw -d imdb_reviews/movie_reviews_train.vw \\\n",
    "--loss_function hinge --ngram 2 -f imdb_reviews/movie_reviews_model2.vw --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!vw -i imdb_reviews/movie_reviews_model2.vw -t -d imdb_reviews/movie_reviews_valid.vw \\\n",
    "-p imdb_reviews/movie_valid_pred2.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('imdb_reviews/movie_valid_pred2.txt') as pred_file:\n",
    "    valid_prediction = [float(label) \n",
    "                             for label in pred_file.readlines()]\n",
    "print(\"Accuracy: {}\".format(round(accuracy_score(valid_labels, \n",
    "               [int(pred_prob > 0) for pred_prob in valid_prediction]), 3)))\n",
    "print(\"AUC: {}\".format(round(roc_auc_score(valid_labels, valid_prediction), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!vw -i imdb_reviews/movie_reviews_model2.vw -t -d imdb_reviews/movie_reviews_test.vw \\\n",
    "-p imdb_reviews/movie_test_pred2.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('imdb_reviews/movie_test_pred2.txt') as pred_file:\n",
    "    test_prediction2 = [float(label) \n",
    "                             for label in pred_file.readlines()]\n",
    "print(\"Accuracy: {}\".format(round(accuracy_score(y_test, \n",
    "               [int(pred_prob > 0) for pred_prob in test_prediction2]), 3)))\n",
    "print(\"AUC: {}\".format(round(roc_auc_score(y_test, test_prediction2), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что биграммы помогли повысить качество классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 4. Применение Vowpal Wabbit к данным по посещению сайтов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузим созданные ранее pickle-объекты, соответствующие разреженным данным [соревнования](https://inclass.kaggle.com/c/identify-me-if-you-can-yandex-mipt/data), которые мы создали на прошлой неделе.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('kaggle_data/X_train_sparse.pkl', 'rb') as X_train_sparse_pkl:\n",
    "    X_train_sparse = pickle.load(X_train_sparse_pkl)\n",
    "with open('kaggle_data/X_test_sparse.pkl', 'rb') as X_test_sparse_pkl:\n",
    "    X_test_sparse = pickle.load(X_test_sparse_pkl)\n",
    "with open('kaggle_data/train_target.pkl', 'rb') as train_target_pkl:\n",
    "    y = pickle.load(train_target_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vowpal Wabbit любит, чтоб метки классов были распределены от 1 до K, где K – число классов в задаче классификации (в нашем случае – 550). Поэтому придется применить LabelEncoder, да еще и +1 потом добавить (LabelEncoder переводит метки в диапозон от 0 до K-1).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_encoder = LabelEncoder().fit(y.astype('str'))\n",
    "y_for_vw = class_encoder.transform(y.astype('str')) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выделим обучающую и оставленную части исходной обучающей выборки.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_sparse, y_for_vw, test_size=0.3, \n",
    "                                                     random_state=7, stratify=y_for_vw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Реализуйте функцию, переводящую разреженную матрицу в формат Vowpal Wabbit.**\n",
    "\n",
    "Вход:\n",
    " - X_sparse – разреженная матрица SciPy.sparse.csr_matrix\n",
    " - y (необяз.) – вектор ответов. Необязателен, поскольку тестовую матрицу будем обрабатывать этой же функцией\n",
    " - out_file – путь к файлу .vw, в который будет произведена запись\n",
    " \n",
    "Детали:\n",
    "- можно делать по-разному, но скорее всего помогут атрибуты *data* и *indices* разреженной матрицы. Обратите внимание на особенность (или баг?) csr_matrix: если признак 8 попадается 3 раза, ему в паре *data* и *indices* могут быть соответвствовать как [3] в *data* и [8] в *indices*, так и [1,1,1] в *data* и [8,8,8] в *indices*.\n",
    "- в тестовой выборке на месте меток целевого класса можно писать произвольные, допустим, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sparse_row_to_vw(x_row, y_row):\n",
    "    x_label = \" \".join(\n",
    "                [\"{}:{}\".format(int(site) + 1, int(count)) for site, count in zip(x_row.indices, x_row.data)])\n",
    "    res = str(y_row or \"\") + \" | sites \" + x_label + \"\\n\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sparse_matrix_to_vw(X_sparse, y=None, out_file='tmp.vw'):\n",
    "    if y is None:\n",
    "        y = [1] * X_sparse.shape[0]\n",
    "    with open(out_file, \"w\") as f_out:\n",
    "        for x_row, y_row in zip(X_sparse, y):\n",
    "            f_out.write(sparse_row_to_vw(x_row, y_row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примените написанную функцию к части обучающей выборки (X_train, y_train), к отложенной выборке (X_valid, y_valid), ко всей обучающей выборке (X_train_sparse, y_for_vw) и ко всей тестовой выборке X_test_sparse.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sparse_matrix_to_vw(X_train, y_train, 'kaggle_data/train_part.vw')\n",
    "sparse_matrix_to_vw(X_valid, y_valid, 'kaggle_data/valid.vw')\n",
    "sparse_matrix_to_vw(X_train_sparse, y_for_vw, 'kaggle_data/train.vw')\n",
    "sparse_matrix_to_vw(X_test_sparse, out_file='kaggle_data/test.vw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Первые 3 строки из каждого файла должны получиться примерно такими (с точностью до нумерации сайтов). **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head -3 kaggle_data/train_part.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head -3 kaggle_data/valid.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head -3 kaggle_data/train.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head -3 kaggle_data/test.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучим модель Vowpal Wabbit со следующими аргументами:**\n",
    "\n",
    " - -d, путь к обучающей выборке (соотв. файл .vw )\n",
    " - --loss_function – hinge (хотя можно и поэкспериментировать с другими)\n",
    " - -f – путь к файлу, в который запишется модель (можно тоже в формате .vw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!vw -d imdb_reviews/movie_reviews_train.vw \\\n",
    "--loss_function hinge -f imdb_reviews/movie_reviews_model.vw --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сделаем прогноз для отложенной выборки с помощью обученной модели Vowpal Wabbit, передав следующие аргументы:**\n",
    " - -i –путь к обученной модели (соотв. файл .vw)\n",
    " - -t -d – путь к отложенной выборке (соотв. файл .vw)\n",
    " - -p – путь к txt-файлу, куда запишутся прогнозы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!vw -i imdb_reviews/movie_reviews_model.vw -t -d imdb_reviews/movie_reviews_valid.vw \\\n",
    "-p imdb_reviews/movie_valid_pred.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучите модель на выборке kaggle_data/train_part.vw. Укажите, что решается задача классификации с 550 классами (*--oaa*), сделайте 10 проходов по выборке (*--passes*). Задайте некоторый кэш-файл (*--cache_file*), так VW будет быстрее делать все следующие после первого проходы по выборке (прошлый кэш-файл удаляется с помощью аргумента *-k*). Также укажите значение параметра b=26. Это число бит, используемых для хэширования, в данном случае нужно больше, чем 18 по умолчанию. Остальные параметры пока не меняйте, далее уже в свободном режиме соревнования можете попробовать другие функции потерь.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 407 ms, sys: 20 ms, total: 427 ms\n",
      "Wall time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw --oaa 550 -d kaggle_data/train_part.vw --passes 10 -b 26 --cache_file kaggle_data/train_part.vw_cache -k \\\n",
    "-f kaggle_data/users_model.vw --quiet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Запишите прогнозы на выборке *kaggle_data/valid.vw* в *kaggle_data/vw_valid_pred.csv*. Укажите random seed = 7.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 ms, sys: 0 ns, total: 16.7 ms\n",
      "Wall time: 962 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw -i kaggle_data/users_model.vw -t -d kaggle_data/valid.vw \\\n",
    "-p kaggle_data/vw_valid_pred.csv --random_seed 7 --quiet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Считайте прогнозы *kaggle_data/vw_valid_pred.csv*  из файла и посмотрите на долю правильных ответов на отложенной части.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vw_valid_pred = pd.read_csv('kaggle_data/vw_valid_pred.csv', header=None)\n",
    "res = accuracy_score(y_valid, vw_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какой получается доля правильных ответов на отложенной выборке? Запишите в файл *answer6_1.txt*, округлив до 3 знаков после запятой.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, file_address):\n",
    "    with open(file_address, 'w') as out_f:\n",
    "        out_f.write(str(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_answer_to_file(\"{}\".format(round(res, 3)),\n",
    "                     'answer6_1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучите модель с теми же параметрами на всей обучающей выборке – *kaggle_data/train.vw*. При этом укажите новый кэш-файл (--cache_file).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "!vw --oaa 550 ''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сделайте прогноз для тестовой выборки.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "!vw -t ''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Запишите прогноз в файл, примените обратное преобразование меток (был LabelEncoder и потом +1 в меткам) и отправьте решение на Kaggle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='user_id', index_label=\"session_id\"):\n",
    "    # turn predictions into data frame and save as csv file\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прогноз, считанный из файла:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vw_pred = ''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прогноз для отправки на Kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vw_subm = class_encoder.inverse_transform ''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_submission_file(vw_subm,\n",
    "                         'kaggle_data/first_vw_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Полученный результат соответствует бейзлайну \"1st Vowpal Wabbit\" на публичном лидерборде в нашем соревновании Kaggle.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Напутствие"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы познакомились с отличной библиотекой Vowpal Wabbit. Хотя это только начало: в VW реализованы матричные разложение и обучение с подкреплением, тематическое моделирование и активное обучение, name entity recognition и нейронные сети. Если Вам придется как-нибудь обучать модель на терабайте данных, при этом расходуя несколько мегабайт оперативной памяти, Вы наверняка вернетесь к этому тьюториалу (если, конечно, не выпустят библиотеку с более удобным интерфейсом). Хочется верить, что именно эта часть проекта оказалось самой полезной!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пути улучшения\n",
    "На этой неделе опять дается время на соревнование, а также на оформление финального проекта.\n",
    "Что еще можно попробовать:\n",
    " - Использовать ранее построенные признаки для улучшения модели\n",
    " - Настроить параметры Vowpal Wabbit с hyperopt, попробовать другие функции потерь\n",
    " - Попробовать TF-IDF и n-граммы\n",
    "\n",
    "На следующей, заключительной, неделе мы оформим всю работу над проектом в виде одного файла (.pdf или .ipynb) и будем проверять проекты друг друга."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python3]",
   "language": "python",
   "name": "Python [python3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
